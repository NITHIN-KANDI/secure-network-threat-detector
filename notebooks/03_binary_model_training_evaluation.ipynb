{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71335a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module 3: Binary Model Training & Evaluation (Single-Pipeline Bundling)\n",
    "\n",
    "Steps:\n",
    "1. Load processed train/test data (raw CSV + integrity dropped)\n",
    "2. Load and apply preprocessing + PCA artifacts\n",
    "3. Train multiple classifiers with hyperparameter tuning\n",
    "4. Evaluate each on train/validation and test sets\n",
    "5. Assemble a final VotingClassifier ensemble\n",
    "6. Bundle into a single Pipeline: preprocessor → PCA → ensemble\n",
    "7. Save all individual models and the full pipeline\n",
    "\"\"\"\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Paths\n",
    "BASE_DIR      = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "RAW_PATH      = os.path.join(BASE_DIR, 'data', 'raw', 'UNSW_NB15_training-set.csv')\n",
    "PROC_DIR      = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "MODELS_DIR    = os.path.join(BASE_DIR, 'src', 'models')\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c8231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load raw data and drop integrity columns if present\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "for col in ['row_hash', 'attack_cat']:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61aa6619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Train/test split\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3af77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Load fitted preprocessor and PCA\n",
    "preprocessor = joblib.load(os.path.join(PROC_DIR, 'preprocessor.pkl'))\n",
    "pca          = joblib.load(os.path.join(PROC_DIR, 'pca.pkl'))\n",
    "\n",
    "# Apply transforms to raw features\n",
    "X_train_proc = preprocessor.transform(X_train_raw)\n",
    "X_test_proc  = preprocessor.transform(X_test_raw)\n",
    "X_train_pca  = pca.transform(X_train_proc)\n",
    "X_test_pca   = pca.transform(X_test_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "303f7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Define models & search spaces\n",
    "models = {\n",
    "    'lr': LogisticRegression(solver='liblinear', random_state=42),\n",
    "    'rf': RandomForestClassifier(n_jobs=-1, random_state=42),\n",
    "    'xgb': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1, random_state=42),\n",
    "    'lgb': LGBMClassifier(n_jobs=-1, random_state=42)\n",
    "}\n",
    "grids = {\n",
    "    'lr': {'C': [0.01, 0.1, 1, 10]},\n",
    "    'rf': {'n_estimators': [100,200], 'max_depth': [None,10,20]},\n",
    "    'xgb': {'n_estimators':[100,200], 'learning_rate':[0.05,0.1], 'max_depth':[3,6]},\n",
    "    'lgb': {'n_estimators':[100,200], 'learning_rate':[0.05,0.1], 'num_leaves':[31,63]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5337f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr best params: {'C': 10}, AUC: 0.8802\n",
      "rf best params: {'n_estimators': 200, 'max_depth': 20}, AUC: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:41:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb best params: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1}, AUC: 0.9890\n",
      "[LightGBM] [Info] Number of positive: 95472, number of negative: 44800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 140272, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.680621 -> initscore=0.756625\n",
      "[LightGBM] [Info] Start training from score 0.756625\n",
      "lgb best params: {'num_leaves': 63, 'n_estimators': 200, 'learning_rate': 0.1}, AUC: 0.9897\n"
     ]
    }
   ],
   "source": [
    "# 5) Hyperparameter tuning\n",
    "best_models = {}\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "for name, clf in models.items():\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=clf,\n",
    "        param_distributions=grids[name],\n",
    "        n_iter=5,\n",
    "        cv=skf,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train_pca, y_train)\n",
    "    best = search.best_estimator_\n",
    "    best_models[name] = best\n",
    "    print(f\"{name} best params: {search.best_params_}, AUC: {search.best_score_:.4f}\")\n",
    "    joblib.dump(best, os.path.join(MODELS_DIR, f\"{name}_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1ee1829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LR Evaluation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.74      0.70     11200\n",
      "           1       0.87      0.82      0.84     23869\n",
      "\n",
      "    accuracy                           0.79     35069\n",
      "   macro avg       0.76      0.78      0.77     35069\n",
      "weighted avg       0.80      0.79      0.80     35069\n",
      "\n",
      "ROC-AUC: 0.8816\n",
      "Confusion Matrix:\n",
      " [[ 8301  2899]\n",
      " [ 4361 19508]]\n",
      "\n",
      "=== RF Evaluation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92     11200\n",
      "           1       0.95      0.97      0.96     23869\n",
      "\n",
      "    accuracy                           0.95     35069\n",
      "   macro avg       0.95      0.94      0.94     35069\n",
      "weighted avg       0.95      0.95      0.95     35069\n",
      "\n",
      "ROC-AUC: 0.9906\n",
      "Confusion Matrix:\n",
      " [[10096  1104]\n",
      " [  664 23205]]\n",
      "\n",
      "=== XGB Evaluation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91     11200\n",
      "           1       0.94      0.98      0.96     23869\n",
      "\n",
      "    accuracy                           0.94     35069\n",
      "   macro avg       0.94      0.93      0.93     35069\n",
      "weighted avg       0.94      0.94      0.94     35069\n",
      "\n",
      "ROC-AUC: 0.9893\n",
      "Confusion Matrix:\n",
      " [[ 9812  1388]\n",
      " [  569 23300]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LGB Evaluation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91     11200\n",
      "           1       0.95      0.97      0.96     23869\n",
      "\n",
      "    accuracy                           0.95     35069\n",
      "   macro avg       0.95      0.93      0.94     35069\n",
      "weighted avg       0.95      0.95      0.95     35069\n",
      "\n",
      "ROC-AUC: 0.9903\n",
      "Confusion Matrix:\n",
      " [[ 9970  1230]\n",
      " [  627 23242]]\n"
     ]
    }
   ],
   "source": [
    "# 6) Evaluate each on test set\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    y_proba = model.predict_proba(X_test_pca)[:,1]\n",
    "    print(f\"\\n=== {name.upper()} Evaluation ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66d03299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\dorai\\\\OneDrive\\\\Documents\\\\Documents\\\\SEM6\\\\Computer Security\\\\Project_cs\\\\IDS-binary-classification\\\\src\\\\models\\\\voting_ensemble.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) Voting ensemble of all four\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(n, m) for n, m in best_models.items()],\n",
    "    voting='soft', n_jobs=-1\n",
    ")\n",
    "ensemble.fit(X_train_pca, y_train)\n",
    "joblib.dump(ensemble, os.path.join(MODELS_DIR, 'voting_ensemble.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3ab342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ENSEMBLE Evaluation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91     11200\n",
      "           1       0.95      0.98      0.96     23869\n",
      "\n",
      "    accuracy                           0.95     35069\n",
      "   macro avg       0.95      0.93      0.94     35069\n",
      "weighted avg       0.95      0.95      0.95     35069\n",
      "\n",
      "ROC-AUC: 0.9890\n",
      "Confusion Matrix:\n",
      " [[ 9846  1354]\n",
      " [  507 23362]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Evaluate ensemble\n",
    "y_e = ensemble.predict(X_test_pca)\n",
    "p_e = ensemble.predict_proba(X_test_pca)[:,1]\n",
    "print(\"\\n=== ENSEMBLE Evaluation ===\")\n",
    "print(classification_report(y_test, y_e))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, p_e):.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50b62f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skl2onnx in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (1.18.0)\n",
      "Requirement already satisfied: onnxruntime in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (1.22.0)\n",
      "Requirement already satisfied: onnx>=1.2.1 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from skl2onnx) (1.18.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from skl2onnx) (1.6.1)\n",
      "Requirement already satisfied: onnxconverter-common>=1.7.0 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from skl2onnx) (1.13.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from onnxruntime) (2.2.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from onnxruntime) (24.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from onnxruntime) (6.30.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from onnx>=1.2.1->skl2onnx) (4.13.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from scikit-learn>=1.1->skl2onnx) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from scikit-learn>=1.1->skl2onnx) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from scikit-learn>=1.1->skl2onnx) (3.6.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\dorai\\onedrive\\documents\\documents\\sem6\\computer security\\project_cs\\csproject\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.5.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install skl2onnx onnxruntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b71e966",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'split_complex_to_pairs' from 'onnx.helper' (c:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\onnx\\helper.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# in your training notebook / Module 3 script, after you build & save full_pipe:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskl2onnx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_sklearn\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskl2onnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FloatTensorType\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load the full sklearn Pipeline\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\skl2onnx\\__init__.py:16\u001b[39m\n\u001b[32m     12\u001b[39m __model_version__ = \u001b[32m0\u001b[39m\n\u001b[32m     13\u001b[39m __max_supported_opset__ = \u001b[32m21\u001b[39m  \u001b[38;5;66;03m# Converters are tested up to this version.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconvert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_sklearn, to_onnx, wrap_as_onnx_mixin\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_supported_operators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m update_registered_converter, get_model_alias\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_parse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m update_registered_parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\skl2onnx\\convert.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_latest_tested_opset_version\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_topology\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_topology\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils_sklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _process_options\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\skl2onnx\\proto\\__init__.py:22\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# onnx is too old.\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhelper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_complex_to_pairs\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_tensor_fixed\u001b[39m(name, data_type, dims, vals, raw=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Make a TensorProto with specified arguments.  If raw is False, this\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    function will choose the corresponding proto field to store the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m \u001b[33;03m    this case.\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'split_complex_to_pairs' from 'onnx.helper' (c:\\Users\\dorai\\OneDrive\\Documents\\Documents\\SEM6\\Computer Security\\Project_cs\\csproject\\Lib\\site-packages\\onnx\\helper.py)"
     ]
    }
   ],
   "source": [
    "# in your training notebook / Module 3 script, after you build & save full_pipe:\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# Load the full sklearn Pipeline\n",
    "import joblib\n",
    "full_pipe = joblib.load(\"src/models/ids_full_pipeline.pkl\")\n",
    "\n",
    "# Determine number of raw features (p)\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/raw/UNSW_NB15_training-set.csv\")\n",
    "feature_cols = [c for c in df.columns if c not in (\"label\",\"attack_cat\",\"row_hash\")]\n",
    "p = len(feature_cols)\n",
    "\n",
    "# Convert to ONNX\n",
    "initial_type = [(feature_cols[i], FloatTensorType([None,1])) for i in range(p)]\n",
    "# Or use one vector input: FloatTensorType([None, p]) with name \"input\"\n",
    "onnx_model = convert_sklearn(\n",
    "    full_pipe,\n",
    "    initial_types=[(\"input\", FloatTensorType([None, p]))],\n",
    "    options={id(full_pipe): {\"zipmap\": False}}\n",
    ")\n",
    "with open(\"src/models/ids_full_pipeline.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
